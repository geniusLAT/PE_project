# Определитель токсичных высказываний в русском языке

Нами была успешно развёрнута модель на StreamLit. В данный момент она доступна по данному адресу.


Она находится  в докерконтейнере, который подключен в Yandex.Cloud.

![](https://sun9-43.userapi.com/impg/gk7Gxf65SaIjNm3-V1pkuGY1MsDK3_n9vCBPMw/CrJOJn3lcIE.jpg?size=840x439&quality=96&sign=af2b1c01f789aba9a172a3fa1d76e5a9&type=album)

Модель способна определить является ли высказывание токсичным. Она показывает два параметра: вывод (toxic\neutral) и уверенность модели.


Нами был так же написан не только StreamLit, но и fastAPI. Были добавлены тесты, которые определяют отвечает ли нам модель в целом, но
так же проверяют корректность её работы, отправляя заведо токсичный и заведомо не токсичный варианты на наш сайт (который в контейнере).


http://185.84.163.5:8080


<h4><i>Члены команды</i></h4>
<table border="1">
  <tr>
    <td>Члены команды</td>
    <td>ФИО</td>
  </tr>
  <tr>
    <td>1</td>
    <td>Трабер Леонид Алексеевич (Капитан)</td>
  </tr>
  <tr>
    <td>2</td>
    <td>Иванов Михаил Сергеевич</td>
  </tr>
  <tr>
    <td>3</td>
    <td>Режист Моиз</td>
  </tr>
   <tr>
    <td>4</td>
    <td>Шавалиев Александр Маратович</td>
  </tr>
  <tr>
    <td>5</td>
    <td>Маухетдинов Евгений Фанисович</td>
  </tr>
  <tr>
    <td>6</td>
    <td>Надеждин Максим Алексеевич</td>
  </tr>
</table>
