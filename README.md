# Определитель токсичных высказываний в русском языке

Нами была успешно развёрнута модель на StreamLit. В данный момент она доступна по данному адресу.


Она находится  в докерконтейнере, который подключен в Yandex.Cloud.

![](https://sun9-43.userapi.com/impg/gk7Gxf65SaIjNm3-V1pkuGY1MsDK3_n9vCBPMw/CrJOJn3lcIE.jpg?size=840x439&quality=96&sign=af2b1c01f789aba9a172a3fa1d76e5a9&type=album)

Модель способна определить является ли высказывание токсичным. Она показывает два параметра: вывод (toxic\neutral) и уверенность модели.


Нами был так же написан не только StreamLit, но и fastAPI. Были добавлены тесты, которые определяют отвечает ли нам модель в целом, но
так же проверяют корректность её работы, отправляя заведо токсичный и заведомо не токсичный варианты на наш сайт (который в контейнере).


http://185.84.163.5:8080